import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score

# ===================================================================
# 0. ë°ì´í„° ì¤€ë¹„
# ===================================================================
print("--- 0. ë°ì´í„° ì¤€ë¹„ ì‹œì‘ ---")

file_path = 'Screwed-Backend/data/SPN_Climate.csv'
df = pd.read_csv(file_path)

# ìƒì‚°ëŸ‰ ì»¬ëŸ¼ ì´ë¦„ì„ 'yield'ë¡œ í†µì¼
if 'YIELD' in df.columns:
    df = df.rename(columns={'YIELD': 'yield'})

# 'yield' ì»¬ëŸ¼ì˜ NaNì€ 0ìœ¼ë¡œ, ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ì˜ NaNì€ í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°
df['yield'].fillna(0, inplace=True)
df.fillna(df.mean(), inplace=True)

# ğŸ’¡ **ìˆ˜í™•ì´ ìˆëŠ” ë°ì´í„°ë§Œìœ¼ë¡œ í•™ìŠµ**
# ìƒì‚°ëŸ‰ì´ 0ì¸ ë°ì´í„°ëŠ” íšŒê·€ ëª¨ë¸ í•™ìŠµì— ë°©í•´ê°€ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
# ì‹¤ì œ ìˆ˜í™•ì´ ë°œìƒí•œ ë°ì´í„°ë§Œ ì‚¬ìš©í•´ 'ì–¼ë§ˆë‚˜' ìƒì‚°ë˜ëŠ”ì§€ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
df_harvest = df[df['yield'] > 0].copy()

if df_harvest.empty:
    print("ì˜¤ë¥˜: í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜í™• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    # --- ì…ë ¥ ë³€ìˆ˜(X)ì™€ ì •ë‹µ(y) ë¶„ë¦¬ ---
    # X: ìƒì‚°ëŸ‰('yield')ì„ ì œì™¸í•œ ëª¨ë“  ë³€ìˆ˜
    X = df_harvest.drop('yield', axis=1)
    # y: ìƒì‚°ëŸ‰('yield') ë³€ìˆ˜
    y = df_harvest['yield']

    print(f"ì´ {len(df)}ê°œ ë°ì´í„° ì¤‘ ìˆ˜í™•ì´ ìˆëŠ” ë°ì´í„° {len(df_harvest)}ê°œë¥¼ í•™ìŠµì— ì‚¬ìš©í•©ë‹ˆë‹¤.")
    print(f"ì…ë ¥ ë³€ìˆ˜(X)ì˜ í˜•íƒœ: {X.shape}")
    print(f"ì •ë‹µ(y)ì˜ í˜•íƒœ: {y.shape}")

    # --- í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ ---
    # shuffle=Trueë¡œ ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì–´ì£¼ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)
    
    print("--- 0. ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ---\n")


    # ===================================================================
    # 1. XGBoost ëª¨ë¸ í•™ìŠµ
    # ===================================================================
    print("--- 1. XGBoost ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
    
    # XGBoost íšŒê·€ ëª¨ë¸ ìƒì„±
    # n_estimators: ë§Œë“¤ íŠ¸ë¦¬ì˜ ê°œìˆ˜
    # max_depth: íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´
    # learning_rate: í•™ìŠµë¥ 
    model = xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, objective='reg:squarederror')

    # ëª¨ë¸ í•™ìŠµ
    model.fit(X_train, y_train)
    
    print("--- 1. XGBoost ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ---\n")


    # ===================================================================
    # 2. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    # ===================================================================
    print("--- 2. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ ---")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
    y_pred = model.predict(X_test)
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    print(f"âœ… í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): {mae:.4f}")
    print(f"â–¶ í•´ì„: ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì€ ì‹¤ì œê°’ê³¼ í‰ê· ì ìœ¼ë¡œ ì•½ {mae:.4f} ë§Œí¼ ì°¨ì´ë‚©ë‹ˆë‹¤.")
    print(f"âœ… R-squared (RÂ²): {r2:.4f}")
    print(f"â–¶ í•´ì„: ëª¨ë¸ì´ ìƒì‚°ëŸ‰ì˜ ë¶„ì‚°ì„ ì•½ {r2*100:.2f}% ì„¤ëª…í•©ë‹ˆë‹¤. (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)")

    print("--- 2. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ ---\n")


    # ===================================================================
    # 3. ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ
    # ===================================================================
    print("--- 3. ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ì‹œì‘ ---")
    
    # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ê¸° ì‰½ê²Œ DataFrameìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
    results_df = pd.DataFrame({
        'Actual_Yield': y_test,
        'Predicted_Yield': y_pred
    })
    
    # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ë§Œ í‘œì‹œí•˜ë„ë¡ ì„¤ì •
    pd.options.display.float_format = '{:.2f}'.format
    
    print("\n--- ì‹¤ì œ ìƒì‚°ëŸ‰ vs ì˜ˆì¸¡ ìƒì‚°ëŸ‰ ë¹„êµ (ìƒ˜í”Œ 10ê°œ) ---")
    print(results_df.head(10).to_string())

    print("\n--- 3. ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ì™„ë£Œ ---")