import pandas as pd
import numpy as np
import xgboost as xgb
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, r2_score

# ===================================================================
# 0. ë°ì´í„° ì¤€ë¹„: ë¡œë”©, ë³‘í•© ë° ì „ì²˜ë¦¬
# ===================================================================
print("--- 0. ë°ì´í„° ì¤€ë¹„ ì‹œì‘ ---")

# --- íŒŒì¼ ë¡œë”© ---
merged_df = pd.read_csv('Screwed-Backend/data/MERGED_file.csv')

# --- ì „ì²˜ë¦¬ ---
# ì˜ˆì¸¡ ëŒ€ìƒ ì‘ë¬¼ ì„¤ì • (SOYBEAN, MAIZE, WHEAT, RICE ì¤‘ ì„ íƒ)
TARGET_CROP = 'SOYBEAN'
# ë‚˜ë¨¸ì§€ ì‘ë¬¼ë“¤ì€ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì‚­ì œ
other_crops = ['MAIZE', 'WHEAT', 'RICE', 'SOYBEAN']
other_crops.remove(TARGET_CROP)

# âœ… ìˆ˜ì •: CODE, LAT, LONì„ ë°”ë¡œ ì‚­ì œí•˜ì§€ ì•Šê³ , ìœ„ì¹˜ ì‹ë³„ìë¡œ ì‚¬ìš©
columns_to_drop = other_crops
merged_df = merged_df.drop(columns=columns_to_drop, errors='ignore')
merged_df = merged_df.rename(columns={TARGET_CROP: 'yield'})
merged_df.fillna(0, inplace=True)
print(f"ì „ì²˜ë¦¬ í›„ ë°ì´í„° í˜•íƒœ: {merged_df.shape}")
print("--- 0. ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ---\n")


# ===================================================================
# 1. ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„± (ìˆ˜ì •ëœ ë¡œì§)
# ===================================================================
print("--- 1. ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ ---")

def create_sequences_by_location(df, sequence_length=3):
    X_list, y_list = [], []
    # âœ… ìˆ˜ì •: ìœ„ë„ì™€ ê²½ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”
    #    ì´ë ‡ê²Œ í•˜ë©´ ê° ì§€ì—­ë³„ë¡œ ë°ì´í„°ë¥¼ ë”°ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    grouped = df.groupby(['LAT', 'LON'])
    
    print(f"ì´ {grouped.ngroups}ê°œì˜ ê³ ìœ í•œ ìœ„ì¹˜ ê·¸ë£¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    # ê° ìœ„ì¹˜ ê·¸ë£¹ë³„ë¡œ ë°˜ë³µ
    for _, group_df in grouped:
        # ê° ê·¸ë£¹ ë‚´ì—ì„œ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        group_df = group_df.sort_values(by=['YEAR', 'MONTH']).reset_index(drop=True)
        
        # ê¸°í›„ ë°ì´í„° ì»¬ëŸ¼ë§Œ 
        #  (ìœ„ì¹˜/ì‹œê°„/ìˆ˜í™•ëŸ‰ ì •ë³´ ì œì™¸)
        climate_features = [col for col in group_df.columns if col not in ['CODE', 'YEAR', 'MONTH', 'LAT', 'LON', 'yield']]
        
        # ê·¸ë£¹ ì•ˆì— ë°ì´í„°ê°€ ì¶©ë¶„í•  ê²½ìš°ì—ë§Œ ì‹œí€€ìŠ¤ ìƒì„±
        if len(group_df) >= sequence_length:
            for i in range(len(group_df) - sequence_length + 1):
                sequence = group_df.iloc[i : i + sequence_length]
                
                # ì›”ì´ ì—°ì†ì ì¸ì§€ í™•ì¸ (ê°™ì€ ê·¸ë£¹ì´ë¯€ë¡œ ìœ„ì¹˜ëŠ” í•­ìƒ ë™ì¼í•¨)
                is_continuous = all(np.diff(sequence['MONTH'].values) % 12 == 1)
                
                if is_continuous:
                    X_list.append(sequence[climate_features].values)
                    last_month_data = sequence.iloc[-1]
                    y_list.append({
                        'is_harvest': 1 if last_month_data['yield'] > 0 else 0,
                        'yield': last_month_data['yield']
                    })

    if not X_list:
        return np.array([]), pd.DataFrame()
        
    return np.array(X_list), pd.DataFrame(y_list)

# âœ… ìˆ˜ì •ëœ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
X_seq, y_df = create_sequences_by_location(merged_df, sequence_length=3)

# âœ… X_seqê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë°©ì–´ ì½”ë“œ (ê¸°ì¡´ê³¼ ë™ì¼)
if X_seq.shape[0] == 0:
    print("âš ï¸ ì˜¤ë¥˜: ìƒì„±ëœ 3ê°œì›” ì‹œí€€ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    print("ë°ì´í„° íŒŒì¼ì˜ ë‚´ìš©ì„ í™•ì¸í•˜ì—¬ í•œ ì§€ì—­ì— ì—°ì†ëœ 3ê°œì›” ë°ì´í„°ê°€ ì¶©ë¶„íˆ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()
else:
    print(f"âœ… ìƒì„±ëœ 3ê°œì›” ì‹œí€€ìŠ¤ ë°ì´í„° í˜•íƒœ (X): {X_seq.shape}")
    print(f"âœ… ìƒì„±ëœ ì •ë‹µ ë°ì´í„° í˜•íƒœ (y): {y_df.shape}")

# --- ë°ì´í„° ë¶„ë¦¬ (í›ˆë ¨/í…ŒìŠ¤íŠ¸) ---
# (ì´ ë¶€ë¶„ì€ ìˆ˜ì •í•  í•„ìš” ì—†ì´ ê·¸ëŒ€ë¡œ ë‘ì‹œë©´ ë©ë‹ˆë‹¤.)
# 1. XGBoostìš© ì…ë ¥ ë°ì´í„° (3ê°œì›”ì¹˜ ë°ì´í„°ë¥¼ 1ì°¨ì›ìœ¼ë¡œ í¼ì¹¨)
X_flat = X_seq.reshape(X_seq.shape[0], -1)
# 2. LSTMìš© ì…ë ¥ ë°ì´í„° (ì›ë³¸ 3D í˜•íƒœ ìœ ì§€)

# ì •ë‹µ ë°ì´í„° ë¶„ë¦¬
y_clf = y_df['is_harvest'].values
y_reg = y_df['yield'].values

# í›ˆë ¨ì…‹ê³¼ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ë¶„ë¦¬ (stratifyë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€)
X_flat_train, X_flat_test, X_seq_train, X_seq_test, y_clf_train, y_clf_test, y_reg_train, y_reg_test = \
    train_test_split(X_flat, X_seq, y_clf, y_reg, test_size=0.2, random_state=42, stratify=y_clf)

print(f"í›ˆë ¨ ë°ì´í„° í˜•íƒœ (X_flat_train): {X_flat_train.shape}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í˜•íƒœ (X_flat_test): {X_flat_test.shape}")
print("--- 1. ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ ---\n")


# ===================================================================
# 2. ëª¨ë¸ 1: ìˆ˜í™•ì›” ì˜ˆì¸¡ (XGBoost ë¶„ë¥˜ ëª¨ë¸)
# ===================================================================
print("--- 2. XGBoost ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")

# ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°
scale_pos_weight = (y_clf_train == 0).sum() / (y_clf_train == 1).sum()
print(f"ì ìš©ë  ê°€ì¤‘ì¹˜ (scale_pos_weight): {scale_pos_weight:.2f}")

# XGBoost ë¶„ë¥˜ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
classifier = xgb.XGBClassifier(
    objective='binary:logistic',
    scale_pos_weight=scale_pos_weight,
    eval_metric='logloss'
)
classifier.fit(X_flat_train, y_clf_train)
print("âœ… ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

# --- ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ---
y_clf_pred = classifier.predict(X_flat_test)
print("\n--- ğŸ“ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ---")
print(classification_report(y_clf_test, y_clf_pred, target_names=['ìˆ˜í™• ì•ˆí•¨ (0)', 'ìˆ˜í™•í•¨ (1)']))

# í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
plt.figure(figsize=(6, 4))
cm = confusion_matrix(y_clf_test, y_clf_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['ìˆ˜í™• ì•ˆí•¨', 'ìˆ˜í™•í•¨'], yticklabels=['ìˆ˜í™• ì•ˆí•¨', 'ìˆ˜í™•í•¨'])
plt.title('ë¶„ë¥˜ ëª¨ë¸ í˜¼ë™ í–‰ë ¬ (Confusion Matrix)')
plt.ylabel('ì‹¤ì œ ê°’')
plt.xlabel('ì˜ˆì¸¡ ê°’')
plt.tight_layout()
plt.savefig('confusion_matrix.png')
print("âœ… 'confusion_matrix.png' íŒŒì¼ë¡œ í˜¼ë™ í–‰ë ¬ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ")
print("--- 2. XGBoost ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ---\n")


# ===================================================================
# 3. ëª¨ë¸ 2: ìƒì‚°ëŸ‰ ì˜ˆì¸¡ (LSTM íšŒê·€ ëª¨ë¸)
# ===================================================================
print("--- 3. LSTM íšŒê·€ ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")

# --- LSTMìš© ë°ì´í„° ì¤€ë¹„ (ìˆ˜í™•ì´ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§ ë° ì •ê·œí™”) ---
X_seq_train_harvest = X_seq_train[y_clf_train == 1]
y_reg_train_harvest = y_reg_train[y_clf_train == 1]

if len(X_seq_train_harvest) > 0:
    # ì •ê·œí™” (Scaler)
    # 3D ë°ì´í„°ë¥¼ 2Dë¡œ í¼ì³ì„œ scaler í•™ìŠµ í›„, ë‹¤ì‹œ 3Dë¡œ ë³µì›
    scaler_X = MinMaxScaler()
    X_train_2d = X_seq_train_harvest.reshape(-1, X_seq_train_harvest.shape[2])
    scaler_X.fit(X_train_2d)
    X_train_scaled_2d = scaler_X.transform(X_train_2d)
    X_train_scaled_3d = X_train_scaled_2d.reshape(X_seq_train_harvest.shape)
    
    scaler_y = MinMaxScaler()
    y_train_scaled = scaler_y.fit_transform(y_reg_train_harvest.reshape(-1, 1))
    
    # PyTorch í…ì„œë¡œ ë³€í™˜
    X_reg_tensor = torch.from_numpy(X_train_scaled_3d).float()
    y_reg_tensor = torch.from_numpy(y_train_scaled).float()

    # --- LSTM ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ ---
    class LSTMRegressor(nn.Module):
        def __init__(self, input_size, hidden_size=50):
            super(LSTMRegressor, self).__init__()
            self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, num_layers=2, dropout=0.2)
            self.fc = nn.Linear(hidden_size, 1)
        def forward(self, x):
            lstm_out, _ = self.lstm(x)
            return self.fc(lstm_out[:, -1, :])

    regressor = LSTMRegressor(input_size=X_seq.shape[2])
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(regressor.parameters(), lr=0.005)

    epochs = 150
    print("LSTM ëª¨ë¸ í•™ìŠµ ì¤‘...")
    for epoch in range(epochs):
        regressor.train()
        outputs = regressor(X_reg_tensor)
        loss = criterion(outputs, y_reg_tensor)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if (epoch + 1) % 30 == 0:
            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}')
    print("âœ… íšŒê·€ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
else:
    regressor = None
    print("âš ï¸ ê²½ê³ : LSTM ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜í™• ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
print("--- 3. LSTM íšŒê·€ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ---\n")


# ===================================================================
# 4. í†µí•© ì˜ˆì¸¡ ë° ìµœì¢… í‰ê°€
# ===================================================================
print("--- 4. í†µí•© ì˜ˆì¸¡ ë° ìµœì¢… í‰ê°€ ì‹œì‘ ---")

final_predictions = []
regressor.eval() if regressor else None

with torch.no_grad():
    for i in range(len(X_flat_test)):
        # 1ë‹¨ê³„: ë¶„ë¥˜ ëª¨ë¸ë¡œ ìˆ˜í™• ì—¬ë¶€ ì˜ˆì¸¡
        is_harvest_pred = classifier.predict(X_flat_test[[i]])[0]
        
        predicted_yield = 0.0
        if is_harvest_pred == 1 and regressor:
            # 2ë‹¨ê³„: LSTMìœ¼ë¡œ ìƒì‚°ëŸ‰ ì˜ˆì¸¡
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ í›ˆë ¨ ì‹œ ì‚¬ìš©í•œ scalerë¡œ ì •ê·œí™”
            X_seq_sample_scaled = scaler_X.transform(X_seq_test[i].reshape(-1, X_seq.shape[2]))
            X_seq_sample_tensor = torch.from_numpy(X_seq_sample_scaled.reshape(1, X_seq.shape[1], X_seq.shape[2])).float()
            
            yield_pred_scaled = regressor(X_seq_sample_tensor)
            # ì˜ˆì¸¡ê°’ì„ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³µì›
            predicted_yield = scaler_y.inverse_transform(yield_pred_scaled.numpy())[0][0]
        
        final_predictions.append(predicted_yield)

# --- ìµœì¢… ì„±ëŠ¥ ìš”ì•½ ---
results_df = pd.DataFrame({
    'Actual_Harvest': y_clf_test,
    'Actual_Yield': y_reg_test,
    'Predicted_Yield': final_predictions
})

# ì‹¤ì œ ìˆ˜í™•ì´ ìˆì—ˆë˜ ë°ì´í„°ë§Œ í•„í„°ë§í•˜ì—¬ íšŒê·€ ì„±ëŠ¥ í‰ê°€
harvest_samples_df = results_df[results_df['Actual_Harvest'] == 1]
if not harvest_samples_df.empty:
    mae = mean_absolute_error(harvest_samples_df['Actual_Yield'], harvest_samples_df['Predicted_Yield'])
    r2 = r2_score(harvest_samples_df['Actual_Yield'], harvest_samples_df['Predicted_Yield'])
    print("\n--- ğŸ“ íšŒê·€ ëª¨ë¸ ìµœì¢… ì„±ëŠ¥ (ì‹¤ì œ ìˆ˜í™•ì´ ìˆì—ˆë˜ ê²½ìš°) ---")
    print(f"í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): {mae:.2f}")
    print(f"R-squared (RÂ²): {r2:.4f}")

    # ìµœì¢… ê²°ê³¼ ì‹œê°í™”
    plt.figure(figsize=(8, 8))
    plt.scatter(harvest_samples_df['Actual_Yield'], harvest_samples_df['Predicted_Yield'], alpha=0.6)
    plt.plot([harvest_samples_df['Actual_Yield'].min(), harvest_samples_df['Actual_Yield'].max()],
             [harvest_samples_df['Actual_Yield'].min(), harvest_samples_df['Actual_Yield'].max()],
             'r--', lw=2, label='Perfect Prediction')
    plt.title(f'{TARGET_CROP} ì‹¤ì œ ìƒì‚°ëŸ‰ vs ì˜ˆì¸¡ ìƒì‚°ëŸ‰')
    plt.xlabel('ì‹¤ì œ ìƒì‚°ëŸ‰')
    plt.ylabel('ì˜ˆì¸¡ ìƒì‚°ëŸ‰')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('final_prediction_scatter.png')
    print("âœ… 'final_prediction_scatter.png' íŒŒì¼ë¡œ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ")
else:
    print("\n[íšŒê·€ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½]")
    print("í‰ê°€í•  ìˆ˜í™• ìƒ˜í”Œì´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ì—†ìŠµë‹ˆë‹¤.")

print("--- 4. í†µí•© ì˜ˆì¸¡ ë° ìµœì¢… í‰ê°€ ì™„ë£Œ ---")