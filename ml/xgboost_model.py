import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import xgboost as xgb
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, r2_score

# ===================================================================
# 0. ë°ì´í„° ì¤€ë¹„
# ===================================================================
print("--- 0. ë°ì´í„° ì¤€ë¹„ ì‹œì‘ ---")
file_path = 'Screwed-Backend/data/MERGED_file.csv' # ì‚¬ìš©í•˜ì‹œëŠ” íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”.
df = pd.read_csv(file_path)

columns_to_drop = ['CODE', 'YEAR', 'LAT', 'LON', 'MAIZE', 'WHEAT', 'RICE']
df = df.drop(columns=columns_to_drop, errors='ignore')

if 'SOYBEAN' in df.columns:
    df = df.rename(columns={'SOYBEAN': 'yield'})
df['yield'] = df['yield'].fillna(0)
df.fillna(df.mean(), inplace=True)

# LSTM ëª¨ë¸ì˜ input_sizeë¥¼ ìœ„í•´ MONTHë¥¼ ì œì™¸í•˜ê¸° ì „ì˜ num_featuresë¥¼ ì €ì¥
num_features_lstm = df.shape[1] 

# ì •ê·œí™”ëœ ë°ì´í„° ìƒì„± (LSTM í•™ìŠµ ë° ì˜ˆì¸¡ì— ì‚¬ìš©)
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df)
scaled_df = pd.DataFrame(scaled_data, columns=df.columns)
print("--- 0. ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ---\n")


# ===================================================================
# 1. ëª¨ë¸ 1: ìˆ˜í™• ì—¬ë¶€ ì˜ˆì¸¡ (XGBoost ë¶„ë¥˜ ëª¨ë¸)
# ===================================================================
print("--- 1. XGBoost ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
# ì…ë ¥(X): 'yield'ì™€ 'MONTH'ë¥¼ ì œì™¸í•œ ëª¨ë“  ë³€ìˆ˜
X_clf = df.drop(['yield', 'MONTH'], axis=1)
# ì •ë‹µ(y): 'yield'ê°€ 0ë³´ë‹¤ í¬ë©´ 1, ì•„ë‹ˆë©´ 0
y_clf = (df['yield'] > 0).astype(int)

X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf)

# ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°
scale_pos_weight = (y_clf_train == 0).sum() / (y_clf_train == 1).sum()

# XGBoost ëª¨ë¸ ë° GridSearchCV ì„¤ì •
param_grid = {'max_depth': [3, 5], 'learning_rate': [0.1], 'n_estimators': [100]}
xgb_model = xgb.XGBClassifier(objective='binary:logistic', scale_pos_weight=scale_pos_weight, eval_metric='logloss')
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='f1', cv=3, verbose=0)
grid_search.fit(X_clf_train, y_clf_train)

best_classifier = grid_search.best_estimator_
print(f"âœ… ìµœì ì˜ íŒŒë¼ë¯¸í„°: {grid_search.best_params_}")

# ===================================================================
# âœ… 1-1. ìµœì í™”ëœ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (ì¶”ê°€ëœ ë¶€ë¶„)
# ===================================================================
# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = best_classifier.predict(X_clf_test)

print("\n--- ë¶„ë¥˜ ëª¨ë¸ ì •ë°€ ì§„ë‹¨ ë¦¬í¬íŠ¸ ---")
# y_true -> y_clf_test, y_pred -> y_pred ë¡œ ë³€ìˆ˜ëª…ì„ ë§ì¶°ì¤ë‹ˆë‹¤.
print(classification_report(y_clf_test, y_pred, target_names=['No_Harvest (0)', 'Harvest (1)']))

print("--- í˜¼ë™ í–‰ë ¬ (Confusion Matrix) ---")
# [[TN, FP],
#  [FN, TP]]
cm = confusion_matrix(y_clf_test, y_pred)
print(cm)
print("í•´ì„: Harvest(1) í´ë˜ìŠ¤ì˜ recall ì ìˆ˜ê°€ ëª¨ë¸ì´ ì‹¤ì œ ìˆ˜í™•í•˜ëŠ” ë‹¬ì„ ì–¼ë§ˆë‚˜ ì˜ ë§ì¶”ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
# ===================================================================

print("--- 1. XGBoost ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ---\n")

# ===================================================================
# 2. ëª¨ë¸ 2: ìƒì‚°ëŸ‰ ì˜ˆì¸¡ (íšŒê·€ LSTM ëª¨ë¸)
# ===================================================================
print("--- 2. íšŒê·€ LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
# ìƒì‚°ëŸ‰ì´ 0ë³´ë‹¤ í° ë°ì´í„°ë§Œ í•„í„°ë§ (ì •ê·œí™”ëœ ë°ì´í„° ì‚¬ìš©)
harvest_only_df = scaled_df[df['yield'].values > 0]

X_reg, y_reg = [], []
for i in range(len(harvest_only_df) - 1):
    X_reg.append(harvest_only_df.iloc[i].values)
    y_reg.append(harvest_only_df.iloc[i + 1].values)

if len(X_reg) > 0:
    X_reg = np.array(X_reg).reshape(-1, 1, num_features_lstm)
    y_reg = np.array(y_reg)
    X_reg_tensor = torch.from_numpy(X_reg).float()
    y_reg_tensor = torch.from_numpy(y_reg).float()

    class LSTMModel(nn.Module):
        def __init__(self, input_size, hidden_size, output_size):
            super(LSTMModel, self).__init__()
            self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
            self.fc = nn.Linear(hidden_size, output_size)
        def forward(self, x):
            lstm_out, _ = self.lstm(x)
            return self.fc(lstm_out[:, -1, :])

    regressor = LSTMModel(input_size=num_features_lstm, hidden_size=50, output_size=num_features_lstm)
    criterion_reg = nn.MSELoss()
    optimizer_reg = torch.optim.Adam(regressor.parameters(), lr=0.001)

    epochs = 100
    for epoch in range(epochs):
        outputs = regressor(X_reg_tensor)
        loss = criterion_reg(outputs, y_reg_tensor)
        optimizer_reg.zero_grad()
        loss.backward()
        optimizer_reg.step()
    print(f"LSTM ìµœì¢… Loss: {loss.item():.4f}")
else:
    regressor = None
    print("ê²½ê³ : LSTM ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜í™• ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
print("--- 2. íšŒê·€ LSTM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ---\n")


# ===================================================================
# 3. í†µí•© ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ (ê°•í™” ë²„ì „)
# ===================================================================
print("--- 3. í†µí•© ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì‹œì‘ ---")

results_list = []

new_threshold = 0.65
print(f"âœ… ìˆ˜í™• íŒë‹¨ ê¸°ì¤€(Threshold)ì´ {new_threshold*100:.0f}%ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n")

if regressor is not None:
    regressor.eval()

# torch.no_grad() ë¸”ë¡ì€ PyTorch ëª¨ë¸ì„ ì‚¬ìš©í•  ë•Œë§Œ í•„ìš”
with torch.no_grad():
    # ì „ì²´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸(X_clf_test)ì— ëŒ€í•´ ë°˜ë³µ
    for i in range(len(X_clf_test)):
        
        input_clf_df = X_clf_test.iloc[[i]]
        
        # --- 1ë‹¨ê³„: XGBoostë¡œ ìˆ˜í™• ì—¬ë¶€ ì˜ˆì¸¡ ---
        # predict_proba()ëŠ” [ìˆ˜í™• ì•ˆí•  í™•ë¥ , ìˆ˜í™•í•  í™•ë¥ ]ì„ ë°˜í™˜
        harvest_probability = best_classifier.predict_proba(input_clf_df)[0][1]
        predicted_harvest = 1 if harvest_probability >= new_threshold else 0

        # --- 2ë‹¨ê³„: 'ìˆ˜í™•í•¨(1)'ìœ¼ë¡œ ì˜ˆì¸¡ë  ë•Œë§Œ LSTMìœ¼ë¡œ ìƒì‚°ëŸ‰ ì˜ˆì¸¡ ---
        predicted_yield = 0.0
        if predicted_harvest == 1 and regressor is not None:
            original_data_index = input_clf_df.index[0]
            
            input_reg_np = scaled_df.iloc[original_data_index].values
            input_reg = torch.from_numpy(input_reg_np).float()

            next_state_scaled = regressor(input_reg.reshape(1, 1, num_features_lstm))
            next_state_original = scaler.inverse_transform(next_state_scaled.numpy())
            
            yield_col_index = df.columns.get_loc('yield')
            predicted_yield = next_state_original[0, yield_col_index]

        # --- ê²°ê³¼ ê¸°ë¡ ---
        original_data_index = input_clf_df.index[0]
        original_row = df.iloc[original_data_index]
        month = original_row['MONTH']
        actual_yield = original_row['yield']
        # ì‹¤ì œ ìˆ˜í™• ì—¬ë¶€ (0 ë˜ëŠ” 1)
        actual_harvest = y_clf_test.iloc[i]
        
        results_list.append({
            'Month': int(month),
            'Actual_Harvest': actual_harvest,
            'Predicted_Harvest': predicted_harvest,
            'Harvest_Probability(%)': harvest_probability * 100,
            'Actual_Yield': actual_yield,
            'Predicted_Yield': predicted_yield,
        })

# --- ìµœì¢… ê²°ê³¼ ë¶„ì„ ---
results_df = pd.DataFrame(results_list)

print("\n--- ğŸ“ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸í‘œ (ìƒìœ„ 20ê°œ) ---")
pd.options.display.float_format = '{:.2f}'.format
print(results_df.head(20).to_string())

print("\n\n" + "="*50)
print("--- ğŸ“Š ìµœì¢… ì„±ëŠ¥ ìš”ì•½ ---")
print("="*50)

# 1. ë¶„ë¥˜ ëª¨ë¸ì˜ ìµœì¢… ì„±ëŠ¥ (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì „ì²´ ëŒ€ìƒ)
print("\n[ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½]")
print(classification_report(results_df['Actual_Harvest'], results_df['Predicted_Harvest'], target_names=['No_Harvest (0)', 'Harvest (1)']))

# 2. íšŒê·€ ëª¨ë¸ì˜ ìµœì¢… ì„±ëŠ¥ (ì‹¤ì œë¡œ ìˆ˜í™•ì´ ìˆì—ˆë˜ ìƒ˜í”Œ ëŒ€ìƒ)
# ì‹¤ì œ ìˆ˜í™•ì´ ìˆì—ˆë˜ ë°ì´í„°ë§Œ í•„í„°ë§
harvest_samples_df = results_df[results_df['Actual_Harvest'] == 1]

if not harvest_samples_df.empty:
    mae = mean_absolute_error(harvest_samples_df['Actual_Yield'], harvest_samples_df['Predicted_Yield'])
    r2 = r2_score(harvest_samples_df['Actual_Yield'], harvest_samples_df['Predicted_Yield'])
    print("\n[íšŒê·€ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ (ì‹¤ì œ ìˆ˜í™•ì´ ìˆì—ˆë˜ ê²½ìš°)]")
    print(f"í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): {mae:.2f}")
    print(f"R-squared (RÂ²): {r2:.4f}")
else:
    print("\n[íšŒê·€ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½]")
    print("í‰ê°€í•  ìˆ˜í™• ìƒ˜í”Œì´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ì—†ìŠµë‹ˆë‹¤.")

print("\n--- 3. í†µí•© ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ---")